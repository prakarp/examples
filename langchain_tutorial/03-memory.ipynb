{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c62fe2-ae60-4794-88a2-13c536fe0af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9310f4-70dc-4e84-8702-d6411301edaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26b71c-2f3a-4446-9d2c-4e53f3666262",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./01-basic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b55651-63c7-4286-a99a-45f3feda607f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f11933-113d-45f3-8ee2-ec9b6f9448a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258379b-c071-4c0f-b573-56a190d69862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c4e76-f733-4e85-bb42-4564a3119847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input = \"Hi My name is Lark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fc36d-b46e-41ce-87ff-2cf86861675f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input = \"what is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f815c10-68e7-458e-8a06-e9136b71d974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input = \"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a65d2e-5878-4a85-98af-44d2e5dfe0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b89e67-49c9-4c45-9797-af67ebb9d852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723b852-1a1a-4273-afb1-670add55fd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0978f2-d5aa-44bb-9de1-520cfa76c1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.save_context({ \"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce71c9-ee21-42b7-9311-5cd8393e9426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893e5d7-dfb2-4055-bfcc-c11fbbf2f46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9649a4e8-7492-4ca5-8d07-7a98e7f66492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Not much, just hanging\"},\n",
    "                    {\"output\": \"cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5b04a-d797-4694-b992-a4b6ff70a62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9975eb0-b8d7-4611-81c8-1e110f98f303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9aa602-efe2-4935-af09-158f9f60b499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc251aea-892b-4943-9884-bde48b56d6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c5c0a-0132-4669-8454-27acaa1858da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d5d1b-3a32-48b2-b9a2-fb97046dc3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=5)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# k is the parameter that indicates the size of the conversation buffer in terms of the q&a. \n",
    "# 5 indicates the previous 5 conversations are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019a93f-5031-4957-af00-f539904590b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi, my name is Lark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eeac63-1bc1-41d0-85ed-679bae4ececd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdffd0a-e8b8-43ff-8cb9-9f81a21ddb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a2930-3e8a-4a4c-8c83-e4117e33d60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input = \"didn't I already tell you my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb673d-b0ea-4170-8151-124d475ca4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339cbc3-6d06-4426-8265-7014b866f1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895484b-0520-42cc-b751-9b33729d54fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=100)\n",
    "# llm must be passed so that the number of tokens are calculated differently depending \n",
    "# on the Llm.  The token calculation is smart enough that it is not just the \n",
    "# number of characters in the memory buffer. It is just the number of \"full tokens\"\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2219b-6a80-4733-b1a9-585d9bcd1923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a487d1-59a7-4166-8b2a-b40377f3f30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi, my name is Lark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb62b13-1b7d-496b-b0a2-63da08a21144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e8a93-5a0f-4bfc-b38c-b9ca7e76dc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e86c29-8e75-4598-8910-4c4950327569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "# Ask the AI to summarize the conversation up until this point, by passing the previous context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd354f0-162f-4e33-8307-89b74f3d58b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522b3df-133d-45b0-91c4-f1c37f231b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17270a-3c0a-4d2e-8d86-488a7bacd0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e48ad7-3ae2-493d-9a0b-0b64b22c05f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fec621-16c4-4904-86e9-b8ea7cf9a5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ba3fdd9-4a63-4503-b0a3-52478b1abea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Buffer Memory, BufferWindowMemory, TokenBufferMemory, SummaryBuffer\n",
    "# There are others such as vector data memory, or entity memory. They may also be stored\n",
    "# in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc0534-e9ec-4e27-a3bc-6e4ccca25eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
